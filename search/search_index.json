{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Titans-vision \u00e9 uma nova gera\u00e7\u00e3o de sistema de vis\u00e3o para rob\u00f4s da liga Very Small Size (VSS), desenvolvido com base no projeto vss-vision da equipe RoboCIn</p>"},{"location":"#objetivo","title":"\ud83c\udfaf Objetivo","text":"<ul> <li>O projeto visa detectar e rastrear rob\u00f4s e a bola em tempo real durante partidas de futebol de rob\u00f4s, utilizando t\u00e9cnicas modernas de vis\u00e3o computacional.</li> </ul>"},{"location":"#principais-funcionalidades","title":"\ud83d\udd0d Principais Funcionalidades","text":"<ul> <li>Detec\u00e7\u00e3o precisa de rob\u00f4s e bola no campo de jogo.</li> <li>Processamento de v\u00eddeo em tempo real com baixa lat\u00eanca.</li> <li>Interface gr\u00e1fica intuitiva para visualiza\u00e7\u00e3o e ajustes.</li> </ul>"},{"location":"#tecnologias-utilizadas","title":"\u2699\ufe0f Tecnologias Utilizadas","text":"<ul> <li>OpenCV para processamento de imagens.</li> <li>Qt5 para desenvolvimento da interface gr\u00e1fica.</li> <li>Docker para facilitar a implanta\u00e7\u00e3o e execu\u00e7\u00e3o do sistema.</li> <li>Protocol Buffers para comunica\u00e7\u00e3o eficiente entre m\u00f3dulos.</li> </ul>"},{"location":"#exemplo-de-funcionameto","title":"\ud83d\udcf7 Exemplo de Funcionameto","text":"<p>Sistema de Vis\u00e3o em A\u00e7\u00e3o</p>"},{"location":"visao/","title":"Home","text":"<p>Titans-vision \u00e9 uma nova gera\u00e7\u00e3o de sistema de vis\u00e3o para rob\u00f4s da liga Very Small Size (VSS), desenvolvido com base no projeto vss-vision da equipe RoboCIn</p>"},{"location":"visao/#objetivo","title":"\ud83c\udfaf Objetivo","text":"<ul> <li>O projeto visa detectar e rastrear rob\u00f4s e a bola em tempo real durante partidas de futebol de rob\u00f4s, utilizando t\u00e9cnicas modernas de vis\u00e3o computacional.</li> </ul>"},{"location":"visao/#principais-funcionalidades","title":"\ud83d\udd0d Principais Funcionalidades","text":"<ul> <li>Detec\u00e7\u00e3o precisa de rob\u00f4s e bola no campo de jogo.</li> <li>Processamento de v\u00eddeo em tempo real com baixa lat\u00eanca.</li> <li>Interface gr\u00e1fica intuitiva para visualiza\u00e7\u00e3o e ajustes.</li> </ul>"},{"location":"visao/#tecnologias-utilizadas","title":"\u2699\ufe0f Tecnologias Utilizadas","text":"<ul> <li>OpenCV para processamento de imagens.</li> <li>Qt5 para desenvolvimento da interface gr\u00e1fica.</li> <li>Docker para facilitar a implanta\u00e7\u00e3o e execu\u00e7\u00e3o do sistema.</li> <li>Protocol Buffers para comunica\u00e7\u00e3o eficiente entre m\u00f3dulos.</li> </ul>"},{"location":"visao/#exemplo-de-funcionameto","title":"\ud83d\udcf7 Exemplo de Funcionameto","text":"<p>Sistema de Vis\u00e3o em A\u00e7\u00e3o</p>"},{"location":"visao/1instalar/","title":"1. Installation Guide","text":"<p>This guide explains how to clone, configure, and run the Titans Vision system, either using Docker or by manually compiling on Ubuntu 22.04 LTS.</p>"},{"location":"visao/1instalar/#option-1-using-docker-recommended","title":"\ud83d\udc33 Option 1: Using Docker (recommended)","text":"<ol> <li>Clone the repository:</li> </ol> <p>Open the terminal and run:    <code>bash    git clone https://github.com/team-titans-unb/titans-vision</code></p> <ol> <li> <p>Navigate to the project directory: <code>bash    cd titans-vision</code></p> </li> <li> <p>Build the Docker image:</p> </li> </ol> <p>This script creates the Docker image with all dependencies configured.    <code>bash    ./docker_build</code></p> <ol> <li>Run the system:</li> </ol> <p>Use the command below to run the system. Replace <code>[Camera ID]</code> with the corresponding camera number (e.g., <code>0</code> for <code>/dev/video0</code>).    <code>bash    ./docker_run [Camera ID]</code></p> <p>\ud83d\udd0e Note:    The Camera ID can be found at <code>/dev/video{id}</code>.    If you do not provide an ID, the system will run without using a connected camera.</p> <p></p> <ol> <li>Start field capture:</li> </ol> <p>After the graphical interface opens, click the \u201cStart Capture\u201d button to begin capturing the field view.</p> <p></p>"},{"location":"visao/1instalar/#option-2-manual-compilation-ubuntu-2204-lts","title":"\ud83d\udee0\ufe0f Option 2: Manual Compilation (Ubuntu 22.04 LTS)","text":"<p>If you prefer or need to compile the project manually, follow the instructions below:</p>"},{"location":"visao/1instalar/#1-install-required-dependencies","title":"1. Install required dependencies","text":"<p>From the project root directory, run:</p> <pre><code>./InstallDependencies\n</code></pre> <p>This script will install all libraries and tools required by the system.</p>"},{"location":"visao/1instalar/#2-compile-the-project-using-cmake","title":"2. Compile the project using CMake","text":"<p>In the terminal:</p> <pre><code># From the root of the repository\nmkdir build\ncd build\ncmake ..\nmake\n</code></pre> <p>This process will create the binary files inside the <code>build</code> directory.</p>"},{"location":"visao/1instalar/#3-run-the-system","title":"3. Run the system","text":"<p>From the project root, run:</p> <pre><code>cd src\n./VSS-VISION\n</code></pre>"},{"location":"visao/2campo/","title":"2. Setting Up the Field","text":""},{"location":"visao/2campo/#1-start-titans-vision","title":"1. Start Titans-Vision","text":"<p>Open the terminal and run the following command:</p> <pre><code>./docker_run [Camera ID]\n</code></pre> <p>\ud83d\udd0d Note: The Camera ID can be found at <code>/dev/video {id}</code>. For example: <code>/dev/video 0</code> \u2192 ID = <code>0</code>  \u2757 If no ID is specified, the system will run without a connected camera.</p> <p></p>"},{"location":"visao/2campo/#2-access-the-graphical-interface","title":"2. Access the Graphical Interface","text":"<p>Once the system starts, the main graphical interface will appear.  Click the Start Capture Button to begin capturing images from the field.</p> <p></p>"},{"location":"visao/2campo/#3-access-the-calibration-interface","title":"3. Access the Calibration Interface","text":"<p>Then click the Field Points Calibration Button to begin setting up the field\u2019s position in the image.</p> <p></p>"},{"location":"visao/2campo/#4-adjusting-field-points","title":"4. Adjusting Field Points","text":"<p>After clicking to configure the field, a new window will open showing the image captured by the camera, with four overlaid points \u2014 one for each corner of the field.</p> <p></p> <p>\ud83d\udd39 Near each point, you will see an associated keyboard key (1, 2, 3, 4).  These keys represent the four corners of the field.</p>"},{"location":"visao/2campo/#how-to-adjust-the-points","title":"\ud83d\udccd How to adjust the points:","text":"<ol> <li>Hold down the <code>Alt</code> key on your keyboard.</li> <li>While holding <code>Alt</code>, press the number key corresponding to the point you want to move.</li> <li>Example: If the bottom point is marked with <code>2</code>, press <code>Alt + 2</code>.</li> <li>Now, use the <code>W</code>, <code>A</code>, <code>S</code>, <code>D</code> keys to move the point in the image:</li> <li><code>W</code> \u2192 up </li> <li><code>A</code> \u2192 left </li> <li><code>S</code> \u2192 down  </li> <li><code>D</code> \u2192 right</li> </ol> <p>\ud83d\udcdd Tip: Adjust the points until each one is exactly positioned at the real four corners of the field as projected by the camera.</p>"},{"location":"visao/2campo/#5-save-configuration","title":"5. Save Configuration","text":"<p>After adjusting all four points:</p> <ul> <li>Click the Ok button to save the point positions.</li> </ul> <p>\u2705 The system is now calibrated with the correct corners of the field.</p>"},{"location":"visao/3cores/","title":"3.Color Configuration Guide \u2013 Titans-VISION","text":""},{"location":"visao/3cores/#overview","title":"Overview","text":"<p>This document provides a step-by-step guide to configuring the Titans-VISION system for optimal object detection and tracking. It covers how to fine-tune color segmentation, adjust object detection size filters, and verify accurate tracking of robots and the ball on the field.</p>"},{"location":"visao/3cores/#1-starting-the-vision-system","title":"1. Starting the Vision System","text":"<p>After launching Titans-VISION, activate Field Capture Mode. At the bottom of the camera preview, change the image mode from Original to Segmented.</p> <p>I </p> <p>This allows you to view only the elements detected by the vision system (robots and ball), filtering out unnecessary data or image noise.</p> <p>\ud83c\udfaf Goal: Only robots and the ball should appear in the segmented view, with minimal false positives.</p>"},{"location":"visao/3cores/#2-opening-the-color-segmentation-tool","title":"2. Opening the Color Segmentation Tool","text":"<p>Navigate to the menu bar and click on MagicVision. </p> <p> </p> <p>After this open the Segmented tab, where you'll configure how the system interprets colors and detects \"blobs\" (visual representations of objects).</p> <p> </p>"},{"location":"visao/3cores/#3-entity-detection-configuration","title":"3. Entity Detection Configuration","text":"<p>On the right side of the screen, under Entities, you can set how many objects the system should detect \u2014 such as the ball and the robots (in the example image, 7 entities). Below that, you\u2019ll see options to fine-tune which objects should or shouldn't be detected.</p> <p>The objective is for the system to detect all the tags and robots as accurately as possible.   Keep in mind: these settings vary depending on the lighting conditions and the specific field setup, so they must be adjusted early on.</p> <ul> <li> <p>Click Apply under Entities to preview the new configuration.</p> </li> <li> <p>Click OK (green arrow) to save.</p> </li> </ul>"},{"location":"visao/3cores/#4-using-the-vectorscope-advanced-color-tuning","title":"4. Using the Vectorscope (Advanced Color Tuning)","text":"<p>If the system is misidentifying colors like in the previous image (e.g., confusing light blue with green), go to the Details tab and enable the Vectorscope below the screen.</p> <p>This will display a color spectrum graph where each line corresponds to a detected color.</p> <p></p> <p>You\u2019ll see several white points appear \u2014 these represent the colors the system is detecting. Each line in the graph corresponds to one detected color.</p> <p>To find out which color a line represents, right-click on the line. On the side panel, the corresponding color will be highlighted:</p> <p> </p> <p>You can drag and reposition these lines to change how the system interprets each color.   For example, if you swap the orange and green lines, the system will show the ball as green in the segmented tab.   This is useful when the system has difficulty detecting specific colors correctly.</p>"},{"location":"visao/3cores/#5-adjusting-blob-size-filters","title":"5. Adjusting Blob Size Filters","text":"<p>Still in the initial camera tab, aside from Original and Segmented, there\u2019s also a Tracked mode, which shows the objects the camera is currently tracking:</p> <p> </p> <p>To configure the minimum and maximum size of objects (blobs) the system should consider valid:</p> <ol> <li>Click the settings button to open the configuration menu.</li> </ol> <p> </p> <ol> <li>In the new window, click on the Calibrate Tracking button.</li> </ol> <p> </p> <p>This will open another tab where you can set the minimum and maximum size of blobs that the system should interpret as valid objects.   Once you\u2019re done, click OK to save the settings.</p> <p> </p>"},{"location":"visao/3cores/#6-validation","title":"6. Validation","text":"<p>Return to the Segmented or Tracked view and verify that:</p> <ul> <li> <p>All robots and the ball are detected correctly.</p> </li> <li> <p>No false objects are being captured.</p> </li> <li> <p>Tracking is consistent as objects move.</p> </li> </ul> <p>Adjust parameters as needed to improve performance, especially when field conditions change (e.g., different lighting or backgrounds).</p>"},{"location":"visao/4dado/","title":"4. Receiving Data","text":""},{"location":"visao/4dado/#1-download-the-required-files","title":"1. Download the Required Files","text":"<p>Some files are necessary for the system to function properly.</p> <p>Download the following files and place them in the <code>pb</code> folder of your project:</p> <ol> <li>wrapper.proto</li> <li>messages_robocup_ssl_detection.proto</li> <li>(optional) messages_robocup_ssl_geometry.proto</li> <li>compile.sh</li> </ol> <p>\ud83d\udd0d Note: About GeometryData:  It is responsible for storing field geometry data, such as point positions and field dimensions. Since we are not using this information, you can remove the following line from the <code>wrapper.proto</code> file: <code>proto optional SSL_GeometryData geometry = 2;</code></p>"},{"location":"visao/4dado/#2-compiling-the-proto-files","title":"2. Compiling the <code>.proto</code> Files","text":"<p>The <code>.proto</code> files are Protobuf message definition files. To generate the <code>.py</code> files used by the system, you need to compile these files.</p> <p>To do this, run the <code>compile.sh</code> script inside the <code>pb</code> folder of your project:</p> <pre><code>cd pb\nsh compile.sh\n</code></pre>"},{"location":"visao/4dado/#3-initializing-the-client","title":"3. Initializing the Client","text":"<p>Now that you have the generated <code>.py</code> files, you can initialize the client. The code below shows how to set up and initialize the client that communicates with the vision system.</p> <pre><code>import socket\nimport struct\n\nclass VisionClient:\n    def __init__(self, vision_ip=\"224.5.23.2\", vision_port=10015):\n        # Vision IP and Port settings\n        self.vision_ip = vision_ip\n        self.vision_port = vision_port\n\n        # Create the UDP socket for communication with vision\n        self.vision_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n\n        # Set socket options\n        self.vision_sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        self.vision_sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, 128)\n        self.vision_sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_LOOP, 1)\n\n        # Configure to join multicast group\n        self.vision_sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, struct.pack(\"=4sl\", socket.inet_aton(self.vision_ip), socket.INADDR_ANY))\n\n        # Bind to listen to the vision port\n        self.vision_sock.bind((self.vision_ip, self.vision_port))\n\n        print(f\"Vision client started. Waiting for data at IP: {self.vision_ip}, Port: {self.vision_port}\")\n\n# Initialize the vision client\nclient = VisionClient()\n</code></pre>"},{"location":"visao/4dado/#4-receiving-data_1","title":"4. Receiving Data","text":"<p>Now that the client is initialized, you can start receiving data from the vision system. The code below shows how to receive and process the data.</p> <pre><code>from pb import wrapper_pb2 as wr\n\nclass VisionDataReceiver:\n    def __init__(self, vision_client):\n        self.vision_sock = vision_client.vision_sock\n\n    def receive_frame(self):\n        \"\"\"Receive and decode the packet.\"\"\"\n        data = None\n        while True:\n            try:\n                data, _ = self.vision_sock.recvfrom(1024)\n            except Exception as e:\n                print(f\"Error receiving data: {e}\")\n            if data is not None:\n                break\n\n        if data is not None:\n            try:\n                # Unpack the SSL_WrapperPacket\n                frame = wr.SSL_WrapperPacket().FromString(data)\n\n                # Process robots and balls\n                robots_blue = [(robot.robot_id, robot.x, robot.y, robot.orientation) for robot in frame.detection.robots_blue]\n                robots_yellow = [(robot.robot_id, robot.x, robot.y, robot.orientation) for robot in frame.detection.robots_yellow]\n\n                balls = [(b.x, b.y, b.confidence) for b in frame.detection.balls]\n\n                # Return full structure with robot and ball data\n                return {\n                    \"robots_blue\": robots_blue,\n                    \"robots_yellow\": robots_yellow,\n                    \"balls\": balls\n                }\n\n            except Exception as e:\n                print(f\"Error processing frame: {e}\")\n        return None\n</code></pre>"},{"location":"visao/4dado/#5-example-usage","title":"5. Example Usage","text":"<p>To use the <code>VisionDataReceiver</code> class, you can do the following:</p> <p>```python vision_client = VisionClient()</p> <p>while True:     data_receiver = VisionDataReceiver(vision_client)     frame_data = data_receiver.receive_frame()</p> <pre><code>if frame_data:\n    print(\"Blue Robots: \", frame[\"robots_blue\"])\n    print(\"Yellow Robots: \", frame[\"robots_yellow\"])\n    print(\"Balls: \", frame[\"balls\"])\nelse:\n    print(\"Error receiving data.\")\n</code></pre>"}]}